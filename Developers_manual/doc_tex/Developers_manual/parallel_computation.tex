% =============================================================================
% The CGAL Developers' Manual
% Chapter: Parallel Computation
% -----------------------------------------------------------------------------
% file   : parallel_computation.tex
% authors: Sandhyaa Radhakrishnan <sandhyaa1990@gmail.com>
%          Ophir Setter <ophir.setter@cs.tau.ac.il>
% -----------------------------------------------------------------------------
% $Id: $
% $Date: $
% =============================================================================

\chapter{Parallel Computation\label{chap:parallel_computation}}
\ccChapterRelease{Chapter Version: 1.0}

Certain algorithms in \cgal{} are ideal candidates for performance
enhancement using multi-threading. Threaded implementations of these
can significantly improve their efficiency.
For example, one such algorithm is the divide-and-conquer approach
used to perform Boolean set operations on a set of polygons. It is
naturally recursive and has been parallelized using
OpenMP~2.0. Threaded implementation significantly improves the performance
of the algorithm given the proper hardware and especially with large
amounts of data.

This chapter provides general guidelines for using and implementing
multi-threading in \cgal{}.

% =============================================================================
\section{The OpenMP API\label{sec:openmp}}
% =============================================================================
The OpenMP Application Program Interface (API) supports multi-platform
shared-memory parallel programming in C++ on various
architectures. OpenMP is a portable, scalable model that gives a
simple and flexible interface for developing parallel applications.

In \cgal{} only OpenMP 2.0 is supported (3.0 is not). This is due to
the lack of support of certain prominent compilers in OpenMP 3.0
(Microsoft Visual C++).

% =============================================================================
\section{Controlling the Number of Executing Threads\label{sec:set_num_thread}}
% =============================================================================
The number of threads created can be controlled by setting
\ccc{OMP_NUM_THREADS} environment variable. By default the number of
threads created will be equal to the number of hardware threads
available on the system.

% =============================================================================
\section{Disabling Parallel Computation\label{sec:disable_parallel}}
% =============================================================================
The developer must make sure that if OpenMP is not used the function
still works. He must also provide a specific flag to disable
multi-threading in the package. If the package name is \ccc{XXX} then
if the user defines the \ccc{CGAL_XXX_SERIAL} compilation flag then
the function must use a single thread.
For example, in the \ccc{Boolean_set_operations_2} package the user
can define the \ccc{CGAL_BOOLEAN_SET_OPERATIONS_2_SERIAL} to enable
serial execution.

We need this flag in situations where a user compiles with OpenMP but
does not want to use OpenMP in a certain package. For example, while
trying to use multi-threading at a higher level.

In the future we could allow different multi-threading methods and
allow the user to select the method desired. To this end we could
introduce a general header parallel.h where we introduce the macro
\ccc{CGAL_PARALLEL_METHOD} which can have values like
\ccc{CGAL_PARALLEL_METHOD_OPENMP} or \ccc{CGAL_PARALLEL_METHOD_BOOST}
which are all defined in parallel.h. Then packages can have a macro by
name \ccc{CGAL_PACKAGE_NAME_PARALLEL_METHOD} set to
\ccc{CGAL_PARALLEL_METHOD} by default.
The introduction of parallel.h and what could go into it is to be
discussed.

A few questions arise. How will the \ccc{PARALLEL_METHOD} macros be
defined in parallel.h? Will each have a unique number as value? There
is also the question of default values. What will
\ccc{CGAL_PARALLEL_METHOD} be set to by default? Which will in turn
determine what \ccc{CGAL_PACKAGE_NAME_PARALLEL_METHOD} is set to by
default.

% =============================================================================
\section{Nested Parallelism\label{sec:nested_parallelism}}
% =============================================================================

By default nested parallelism is disabled in OpenMP. When a parallel
region is encountered within another parallel region, new threads are
not created. This means that in recursive calls, new threads are
created when the recursive function is first called and not for
further recursive calls.

However if nested parallelism is enabled by the user, then each
recursive call would result in the creation of threads when the
parallel directive is encountered.
This would result in rapid exponential increase in the number of
threads causing the program to crash.
The developer must make sure that enabling nested parallelism is
supported by the package.
Our recommended approach is to use a member counter. New threads are
created only if this member counter is less
than \ccc{OMP_NUM_THREADS}.

The user can enable nested parallelism by setting the environment
variable \ccc{OMP_NESTED} to true. This will not affect the
performance.

% ==========================================================================================
\section{Parallelizing Divide and Conquer using OpenMP\label{sec:divide_and_conquer_openmp}}
% ==========================================================================================

How to parallelize divide and conquer funtions in some package XXX in CGAL using 
OpenMP? Here we show an example using the general structure of divide and 
conquer algorithms. 

In order to take care of the case where nested parallelism is enabled by the 
user, a member counter should be used \ccc{(m_current_num_threads)} which is 
initially set to 1. We compare the current value of this counter to the value 
returned by \ccc{omp_get_max_threads()} each time \ccc{_divide_and_conquer} is 
called. \ccc{omp_get_max_threads()} returns the value of \ccc{OMP_NUM_THREADS} 
(or the number of hardware threads on the system if it is not set). 

If the current number of threads is less than this, create a parallel region 
with number of threads equal to \ccc{OMP_NUM_THREADS} and then set 
\ccc{m_current_num_threads} to \ccc{OMP_NUM_THREADS}. The omp atomic directive 
identifies a specific memory location that must be updated atomically and not be 
exposed to multiple, simultaneous writing threads. The omp for directive 
instructs the compiler to distribute loop iterations within the team of threads 
that encounters this work-sharing construct. The team of threads run 
simultaneously. At the end of the parallel region, the counter is decremented. 

If the current number of threads is greater than or equal to \ccc{OMP_NUM_THREADS} 
then new threads should not be spawned and the for loop executes serially.
 
\begin{verbatim}
_divide_and_conquer ()
{
  if (some base case)
  {
    conquer ();
    return;
  }

  #if !defined(CGAL_XXX_SERIAL) && defined(_OPENMP)
  if(m_current_num_threads < omp_get_max_threads())
  {
    #pragma omp atomic
    m_current_num_threads += (omp_get_max_threads() - 1);
       
    #pragma omp parallel
    {
      #pragma omp for
      for (int i = 0; i < k; ++i)
      {
        _divide_and_conquer ();
      }         
    } // end omp parallel
        
    m_current_num_threads -= (omp_get_max_threads() - 1);
  } //end if
  else    
  #endif
  {        
    for (unsigned int i = 0; i < k; ++i)
    {
      _divide_and_conquer ();
    }
  }
    
  conquer ();
    
  return;
}
\end{verbatim}

